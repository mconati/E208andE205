{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Marco Conati\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "RSbXDkeq36e1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7520426530164c823f684f174d00e9db",
     "grade": false,
     "grade_id": "cell-7bfac14d0fc05f49",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 3\n",
    "\n",
    "The purpose of this assignment is to give you experience applying gradient descent to slightly more complicated models like logistic regression.  These models will require using the chain rule in order to calculate gradients.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please name your notebook in the following format:\n",
    "\n",
    "**e208-hw3-[your_last_name].ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:17:48.809088Z",
     "start_time": "2020-02-17T23:17:48.530968Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "y19B0OR_36e4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:17:50.119043Z",
     "start_time": "2020-02-17T23:17:49.261003Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7mET4gZm36e9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T21:28:40.132335Z",
     "start_time": "2020-02-10T21:28:40.118857Z"
    },
    "colab_type": "text",
    "id": "ohmx9_KH36fA"
   },
   "source": [
    "### Important:\n",
    "- For autograding purposes, many cells are set in read-only mode. This means you cannot edit, delete, or move these cells.\n",
    "- You should not modify any code except where you see `# YOUR CODE HERE`. Please remove the `raise NotImplementedError()` line and write your code in its place. \n",
    "- You should write your written responses in the designated cells. \n",
    "- We provide code cells that check your code as you progress through the assignment. These tests will help catch obvious errors, but passing these tests is not a guarantee that your implementation is correct. Your notebook will be graded on a more complete set of tests which are not visible to you.\n",
    "- You may add new cells anywhere in the notebook while working, but make sure to delete them before submitting your assignment. Please do not change the sequence of the cells. This is to ensure that autograding works properly.\n",
    "- If you run cells out of order, it may change variable values which may cause tests to fail. The easiest way to avoid this problem is to use the Restart & Run all option available in the Kernel tab. Before submitting, you should do this to ensure that your notebook can be run from beginning to end without errors. This is how your notebook will be graded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "UE6ZH7nx36fA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29541aab4f882c43be13aba0e2a55cf3",
     "grade": false,
     "grade_id": "cell-75a70287195de111",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 1: Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "ZtwZj_L336fB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbb9afbd259a28adf552f7a04d2f73fb",
     "grade": false,
     "grade_id": "cell-ea42dc3c198973ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This problem will give you practice applying the chain rule when calculating gradients.\n",
    "\n",
    "Let's say that we have a model of the form:\n",
    "\n",
    "$$y = log_d ((a x^2 + b x + c)^2)$$\n",
    "\n",
    "where $a$, $b$, $c$, and $d$ are the parameters of the model.  Given a set of data points, we would like to estimate the parameters of the model using batch gradient descent.\n",
    "\n",
    "Let's first generate the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:17:53.455951Z",
     "start_time": "2020-02-17T23:17:53.452001Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "j-KDgMub36fC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f5144a0af8ee6adfc73815b290d0cc",
     "grade": false,
     "grade_id": "cell-01e8e9ddb864d11e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_model_outputs(x, w):\n",
    "    '''\n",
    "    Inputs\n",
    "      x: numpy array containing the independent variable\n",
    "      w: numpy array containing the model parameters\n",
    "      \n",
    "    Returns\n",
    "      y_hat: numpy array containing the model outputs\n",
    "    '''\n",
    "    #Return the value predicted by the model\n",
    "    y_hat = np.log(np.square(w[0] * x*x + w[1]*x + w[2]))/np.log(w[3]) \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:17:55.373387Z",
     "start_time": "2020-02-17T23:17:55.369692Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 2870,
     "status": "ok",
     "timestamp": 1588313796847,
     "user": {
      "displayName": "Mazda Moayeri",
      "photoUrl": "",
      "userId": "03659336037567690961"
     },
     "user_tz": 240
    },
    "id": "t94eMfZ036fE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67f4a5c0c46e7e40c04f34d8a6824810",
     "grade": true,
     "grade_id": "cell-44d208f6cf6c86a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "874661ea-c24e-447b-e303-7bed37accb01"
   },
   "outputs": [],
   "source": [
    "# test of correctness\n",
    "ans = compute_model_outputs(3, [1,4,1,5])\n",
    "assert(np.allclose(ans, 3.8411453209567425, atol=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:17:56.364698Z",
     "start_time": "2020-02-17T23:17:56.353448Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "n3BF3z8e36fI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f12bd51cd780fcd2ff81e3c3e7d4e4a",
     "grade": false,
     "grade_id": "cell-008acb4c5e36811b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_sample_data(params, N, noiseVar):\n",
    "    '''\n",
    "    Inputs\n",
    "      params: a numpy array containing the model parameters a, b, c, d\n",
    "      N: the number of data points to generate\n",
    "      noiseVar: the variance of the noise to add\n",
    "      \n",
    "    Returns\n",
    "      x: numpy array containing the independent variable\n",
    "      y: numpy array containing the dependent variable\n",
    "    '''\n",
    "    assert(len(params) == 4)\n",
    "    a, b, c, d = params\n",
    "    np.random.seed(0)\n",
    "    x = np.random.uniform(-3, 3, N)\n",
    "    noise = np.random.normal(0, noiseVar, N)\n",
    "    y = compute_model_outputs(x, params) + noise\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:17:57.848965Z",
     "start_time": "2020-02-17T23:17:57.840392Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "u7JERUII36fL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e99e719d4a9fe83f06de4413de26caf2",
     "grade": false,
     "grade_id": "cell-97b2a8f2cf9c7214",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "params_true = [.5, 3.7, -4.2, 2.6]\n",
    "N = 30\n",
    "noiseVar = 0.2\n",
    "x, y = generate_sample_data(params_true, N, noiseVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:17:58.588455Z",
     "start_time": "2020-02-17T23:17:58.423143Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 2855,
     "status": "ok",
     "timestamp": 1588313796878,
     "user": {
      "displayName": "Mazda Moayeri",
      "photoUrl": "",
      "userId": "03659336037567690961"
     },
     "user_tz": 240
    },
    "id": "rhIhe-R636fP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24f63d93f4635650374f0ae3dcf7ac4a",
     "grade": false,
     "grade_id": "cell-106417ab7482c051",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "e7e94a2d-162d-411a-8e59-db815320c960"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "oZivuDoC36fS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0230b019062c67b9ab8753b57c97d2e0",
     "grade": false,
     "grade_id": "cell-4d6a1ef3a7e202bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your goal below is to estimate the model coefficients using batch gradient descent with a mean squared error metric.  You may use as many code and markdown cells as needed.  In your work, you should do the following:\n",
    "- Derive an analytical expression for the error gradient.\n",
    "- Complete the compute_grad and grad_checking functions below.  Verify that your implementation passes gradient checking.\n",
    "- Plot MSE vs iteration for three different learning rates (all of which should converge).\n",
    "- Plot the original data points with the estimated curve overlaid.\n",
    "- Provide a discussion of any challenges that you encountered in getting your system to converge to a good solution.\n",
    "\n",
    "Part of your grade will be on the readability of your writeup and code, so be sure to decompose and comment your code accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "Jj82MsGt36fT",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0beb3e70eef1ed32226ae8974d81840f",
     "grade": true,
     "grade_id": "cell-457c6158d9670d12",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "#### Derive an analytical expression for the error gradient:\n",
    "\n",
    "I'll use a computational graph for this. Let's look at the original loss function:\n",
    "\n",
    "loss = $\\frac{1}{N}\\Sigma_{i=1}^n({y}-log_d(ax^2 + bx + c)^2)^2$\n",
    "\n",
    "Splitting this into functions for the computational graph.\n",
    "\n",
    "Let:\n",
    "\n",
    "z = $(ax^2 + bx + c)$   \n",
    "g = $z^2$   \n",
    "p = $log_d(g)$   \n",
    "\n",
    "Then, we can just express our loss as   \n",
    "mse = $\\frac{1}{N}\\Sigma_{i=1}^n({y}-p)^2$  \n",
    "If we rewrite y and p as vectors where  \n",
    "Y = \\begin{bmatrix}\n",
    "y_0&\n",
    "y_1&\n",
    "...&\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "P = \\begin{bmatrix}\n",
    "p_0&\n",
    "p_1&\n",
    "...&\n",
    "p_n\n",
    "\\end{bmatrix}  \n",
    "We can rewrite the sum as:  \n",
    "mse = $\\frac{1}{N}(YY^T -2YP + PP^T)$\n",
    "\n",
    "Taking our derivatives along the computational graph:  \n",
    "First, find the derivative of z with respect to the parameters a,b,c:  \n",
    "$\\frac{dz}{da} = x^2$  \n",
    "$\\frac{dz}{db} = x$  \n",
    "$\\frac{dz}{dc} = 1$\n",
    "\n",
    "Second, find the derivative of g with respect to z:  \n",
    "$\\frac{dg}{dz} = 2z$  \n",
    "\n",
    "Third, take the derivative of p with respect to g and our parameter d:  \n",
    "It was very useful to use the property: $log_d(x) = \\frac {log(x)}{log(d)}$   \n",
    "$\\frac{dp}{dd} = \\frac {log(g)}{(dlog^2(d))}$  \n",
    "$\\frac{dp}{dg} = \\frac {1} {glog(d)}$  \n",
    "\n",
    "Finally, take the derivative of the mean squared error with respect to p. I will call this loss l:  \n",
    "$\\frac{dl}{dp} = \\frac{1}{N}(-2y + 2p)$  \n",
    "\n",
    "Now we can find all of the derivatives of our weights. I'll write out the chain rule for each, but leave the calculation up to the computer(also I used l to represent our loss given by MSE):  \n",
    "$\\frac{dl}{da} = \\frac{dl}{dp}\\frac{dp}{dg}\\frac{dg}{dz}\\frac{dz}{da}$   \n",
    "$\\frac{dl}{db} = \\frac{dl}{dp}\\frac{dp}{dg}\\frac{dg}{dz}\\frac{dz}{db}$   \n",
    "$\\frac{dl}{dc} = \\frac{dl}{dp}\\frac{dp}{dg}\\frac{dg}{dz}\\frac{dz}{dc}$   \n",
    "$\\frac{dl}{dd} = \\frac{dl}{dp}\\frac{dp}{dd}$  \n",
    "\n",
    "Where all the derivaives are defined above. In compute_grad, I use the computer to calculate the value of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:19:54.944124Z",
     "start_time": "2020-02-17T23:19:54.925615Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "stR-Fbpn36fT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1788b7419b38afe04ebf69e359b5795b",
     "grade": true,
     "grade_id": "cell-13caa4a90047853e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_grad(x, y, w):\n",
    "    '''\n",
    "    Inputs\n",
    "      x: numpy array containing the independent variable\n",
    "      y: numpy array containing the target values\n",
    "      w: numpy array containing the model parameters\n",
    "      \n",
    "    Returns\n",
    "      grad: numpy array containing the gradients of w\n",
    "      mse: scalar indicating the mean squared error\n",
    "    '''\n",
    "    # Separate values for readability\n",
    "    N = x.size\n",
    "    a = w[0]\n",
    "    b = w[1]\n",
    "    c = w[2]\n",
    "    d = w[3]\n",
    "    #Plug in values to calculate z,g,p, and mse as defined above\n",
    "    z = a*np.square(x) + b*x + c\n",
    "    g = np.square(z)\n",
    "    p = np.log(g)/np.log(d)\n",
    "    mse = (y.dot(y) - 2*y.dot(p) + p.dot(p))/N\n",
    "    #calculate derivatives at each state\n",
    "    #for my naming convention, dadb means derivative of a with respect to b\n",
    "    #Also, l stands for loss(mse)\n",
    "    dldp = -2*y + 2*p\n",
    "    dpdd = -np.log(g)/(d*np.log(d)*np.log(d))\n",
    "    dpdg = 1/(g*np.log(d))\n",
    "    dgdz = 2*z\n",
    "    dzda = np.square(x)\n",
    "    dzdb = x\n",
    "    dzdc = np.ones_like(x)\n",
    "    #Currently, the derivatives are vector of derivatives for each data point. To get the batch gradients\n",
    "    #Sum them and divide by the number of samples in the batch\n",
    "    dlda = sum(dldp * dpdg * dgdz * dzda)/N\n",
    "    dldb = sum(dldp * dpdg * dgdz * dzdb)/N\n",
    "    dldc = sum(dldp * dpdg * dgdz * dzdc)/N\n",
    "    dldd = sum(dldp * dpdd)/N\n",
    "    #Group them into one gradient\n",
    "    grad = np.array([dlda,dldb,dldc,dldd])\n",
    "    return grad, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09858311,  0.07513076,  0.05820139, -0.07536709])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_grad(x, y, np.array([.5, 3.7, -4.2, 2.6]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:20:30.645685Z",
     "start_time": "2020-02-17T23:20:30.641762Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "VYnpoYQ436fX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eee2ae7b1d0872de91066b2d740f202",
     "grade": true,
     "grade_id": "cell-c10c67fafbb137ac",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test of accuracy \n",
    "assert(np.allclose(compute_grad(x, y, np.array([.5, 3.7, -4.2, 2.6]))[0],\n",
    "                    np.array([ 0.09858311,  0.07513076,  0.05820139, -0.07536709]), rtol = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d042793c965a64a9a4c1c2b893ecd4a",
     "grade": true,
     "grade_id": "cell-c73596c2b6bce649",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(np.allclose(compute_grad(x, y, np.array([.5, 3.7, -4.2, 2.6]))[1], 0.04986061848931964, rtol = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T21:34:39.152732Z",
     "start_time": "2020-02-10T21:34:39.146414Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "CmuMxE0q36fj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee644ca3be75fa8cf3054f0a55561599",
     "grade": true,
     "grade_id": "cell-a56721a5615ec9e3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def grad_checking(x, y, w, eps = 1e-7):\n",
    "    '''\n",
    "    Performs gradient checking on a single (x,y) data point\n",
    "    \n",
    "    Inputs\n",
    "      x: scalar input \n",
    "      y: scalar output\n",
    "      w: model weights\n",
    "      eps: tolerance for gradient checking\n",
    "      \n",
    "    Returns\n",
    "      isCorrect: boolean indicating whether gradient checking passes or fails\n",
    "    '''\n",
    "    x_arr = np.array([x])\n",
    "    y_arr = np.array([y])\n",
    "    grad, _ = compute_grad(x_arr, y_arr, w)\n",
    "    grad_approx = np.zeros_like(grad)\n",
    "    for i in range(len(w)):\n",
    "        delta = np.zeros_like(w) \n",
    "        delta[i] = eps\n",
    "        #Move the weights slightly and find the value\n",
    "        yPlus = np.square(y-compute_model_outputs(x, w + delta))\n",
    "        yMinus = np.square(y-compute_model_outputs(x, w - delta))\n",
    "        #Esimate the derivative\n",
    "        grad_approx[i] = (yPlus - yMinus)/(2*eps)\n",
    "    num = np.linalg.norm(grad - grad_approx)\n",
    "    denom = np.linalg.norm(grad) + np.linalg.norm(grad_approx)\n",
    "    diff = num / denom\n",
    "    if diff < eps:\n",
    "        print('Passes gradient checking')\n",
    "        return True\n",
    "    else:\n",
    "        print('Fails gradient checking')\n",
    "        print(diff)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "vw8Y1soI36fm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8500a15693ff7bfd4d52b6e00624bed",
     "grade": false,
     "grade_id": "cell-2b6b1a5d00170f22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check that your implementation passes gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T21:34:42.996790Z",
     "start_time": "2020-02-10T21:34:42.990076Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1588314344601,
     "user": {
      "displayName": "Mazda Moayeri",
      "photoUrl": "",
      "userId": "03659336037567690961"
     },
     "user_tz": 240
    },
    "id": "BHYHDPB536fm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80df7cdc42beb697448e9e07557110bc",
     "grade": true,
     "grade_id": "cell-cd0e0b9accd39546",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "a935250c-cd07-4237-9fb5-b8963bf706dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passes gradient checking\n"
     ]
    }
   ],
   "source": [
    "assert(grad_checking(x[0], y[0], np.array([-1.2, 2.3, 1.7, 2.6])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a wrapper function that learns the model weights given a set of data and training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeaf4d95e08de131851a2591486f110a",
     "grade": true,
     "grade_id": "cell-ff0452f2320d75e2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_params(x, y, lr, iters, seed = 0):\n",
    "    '''\n",
    "    Learns model weights by minimizing MSE.\n",
    "    \n",
    "    Inputs:\n",
    "        x - inputs\n",
    "        y - target values\n",
    "        lr - learning rate\n",
    "        iters - number of iterations to train\n",
    "        seed - for random number generator\n",
    "        \n",
    "    Returns:\n",
    "        w - estimated model weights\n",
    "        mse_traj - history of MSE vs iteration\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    w = np.random.normal(0, 1, 4) \n",
    "    w[3] = np.random.uniform(1,5) # when initializing, note that d should be > 1 and that log(0) is invalid\n",
    "    mse_traj = []\n",
    "    \n",
    "    for n in range(iters):\n",
    "        N = x.size\n",
    "        a = w[0]\n",
    "        b = w[1]\n",
    "        c = w[2]\n",
    "        d = w[3]\n",
    "        #Plug in values to calculate z,g,p, and in turn mse as defined above\n",
    "        z = a*np.square(x) + b*x + c\n",
    "        g = np.square(z)\n",
    "        p = np.log(g)/np.log(d)\n",
    "        mse = (y.dot(y) - 2*y.dot(p) + p.dot(p))/N\n",
    "        #Use the grad function\n",
    "        grad = compute_grad(x,y,w)[0]\n",
    "        #Alther weights\n",
    "        w = w - lr * grad\n",
    "        mse_traj.append(mse)\n",
    "\n",
    "    mse_traj = np.array(mse_traj)\n",
    "    return w, mse_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a helper function for visualizing a model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T07:33:00.299404Z",
     "start_time": "2020-02-06T07:33:00.278399Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "vUwfmZh936fr",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f3e052203c4305b043a5de74f8453af",
     "grade": false,
     "grade_id": "cell-a6d84a4567b0a641",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def display_losses_and_fit(x, y, w, losses):\n",
    "    '''\n",
    "    Generate two side-by-side figures:\n",
    "      - A plot of MSE vs iteration \n",
    "      - A scatterplot with the fitted quadratic overlaid\n",
    "      \n",
    "    Inputs:\n",
    "        x - inputs\n",
    "        y - target values\n",
    "        w - weights of model\n",
    "        losses - MSE for each epoch\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "    ax1.plot( losses, 'b.')\n",
    "    ax1.set_title('MSE vs. Iteration')\n",
    "\n",
    "    x_pts = np.linspace(min(x), max(x), 300)\n",
    "    pred_y = compute_model_outputs(x_pts, w)\n",
    "    ax2.plot(x_pts, pred_y)\n",
    "    ax2.set_title('Fitted Quadratic')\n",
    "    ax2.scatter(x, y)\n",
    "    plt.show()\n",
    "    print(\"weights \",w)\n",
    "    print(\"final loss, \",losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22b63fcbe8218216872dfd21c3da437a",
     "grade": false,
     "grade_id": "cell-fa2f4d9a8687e86b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Visualize the results using three different learning rates below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T07:33:05.244300Z",
     "start_time": "2020-02-06T07:33:04.422982Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "deletable": false,
    "executionInfo": {
     "elapsed": 436,
     "status": "error",
     "timestamp": 1588314393333,
     "user": {
      "displayName": "Mazda Moayeri",
      "photoUrl": "",
      "userId": "03659336037567690961"
     },
     "user_tz": 240
    },
    "id": "6Ob7pxAd36ft",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "819a97e73f67e241802df3a675c321f0",
     "grade": true,
     "grade_id": "cell-a8d50795ba5edf1d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "ecaedb4d-4a45-44d2-952a-7a494b6161bc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights  [ 23.10106648 -43.11701879  20.40846146   7.9709211 ]\n",
      "final loss,  0.16335757326900763\n"
     ]
    }
   ],
   "source": [
    "# Visualize results with learning rate #1\n",
    "w,mset = estimate_params(x,y,0.1, 100000)\n",
    "display_losses_and_fit(x,y,w,mset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T07:33:07.322148Z",
     "start_time": "2020-02-06T07:33:06.792212Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "deletable": false,
    "executionInfo": {
     "elapsed": 280,
     "status": "error",
     "timestamp": 1588314353418,
     "user": {
      "displayName": "Mazda Moayeri",
      "photoUrl": "",
      "userId": "03659336037567690961"
     },
     "user_tz": 240
    },
    "id": "shaZZgHn36fw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cb50818551b02adc01d1ae0d7e5da05",
     "grade": true,
     "grade_id": "cell-9a3f465540a79bb9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "4588c59a-73c3-4812-966a-2e9de81eaf83"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights  [ 29.20612088 -54.91528754  26.00346659   8.9727332 ]\n",
      "final loss,  0.14855678362492122\n"
     ]
    }
   ],
   "source": [
    "# Visualize results with learning rate #2\n",
    "w,mset = estimate_params(x,y,0.5, 50000)\n",
    "display_losses_and_fit(x,y,w,mset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T07:33:02.945272Z",
     "start_time": "2020-02-06T07:33:01.896317Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "7Aa-Zrbr36fz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a15fc7c0f1aa287394028d35d73c1d14",
     "grade": true,
     "grade_id": "cell-a531f8373329c1d1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights  [ 31.66078318 -59.66423998  28.26303966   9.34992578]\n",
      "final loss,  0.1454944071208312\n"
     ]
    }
   ],
   "source": [
    "# Visualize results with learning rate #3\n",
    "w,mset = estimate_params(x,y,0.9, 40000)\n",
    "display_losses_and_fit(x,y,w,mset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T21:44:49.401304Z",
     "start_time": "2020-02-10T21:44:49.395263Z"
    },
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "BgtLld6A36f1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c7c295b099adef233148e5858175c38",
     "grade": false,
     "grade_id": "cell-5bff875fbf5712d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Provide a discussion of any observations you have and any challenges that you encountered in getting your system to converge to a good solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "6b5JUwTU36f1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc3b8ba22a9f926e25a6fb80dd269706",
     "grade": true,
     "grade_id": "cell-16247cc6e2df7a32",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Write your answers here:**\n",
    "\n",
    "Compared to previous models, this model is more resilient to higher learning rate(doesn't diverge as easily), but takes way more iterations to converge. In previous homeworks, a lr of 0.1 has been good for stable convergence, but in this case, it took tens of thousands of iterations for the model to converge with a lr of 0.1. This is likely because the model is more complicated than previous ones from the class.\n",
    "\n",
    "I was able to get it to converge faster with higher learning rates; surprisingly, convergence seemed stable with a learning rate as high as 0.9. \n",
    "\n",
    "In all three cases, I could've gotten the final loss lower by increasing the number of iterations further. However, it was taking my computer a long time to run. There was definitely a tradeoff between using a more stable learning rate and time/hardware investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "LnxItRGw36f2",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1123a2f1e542017221ed1491e9357226",
     "grade": false,
     "grade_id": "cell-3d5b0577bbfcef51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "_QdKRm0036f2",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77b0085d8aeee29303cd9a87bc5ba09f",
     "grade": false,
     "grade_id": "cell-0873615981f5681d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this problem we will implement logistic regression to predict whether or not a student will get into graduate school.  We will work with a dataset of student admissions at UCLA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:36.933018Z",
     "start_time": "2020-02-17T23:40:36.922398Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qd8VixzK36f3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ucla_admissions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:37.149372Z",
     "start_time": "2020-02-17T23:40:37.137386Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OSjJkIid36f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:37.343635Z",
     "start_time": "2020-02-17T23:40:37.312989Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "p_Seh-zZ36f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa       rank\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "MFQy-RN836gA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c64e84f90012875d54e080f992237b0",
     "grade": false,
     "grade_id": "cell-1ab06ebba4fd73f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So we have data on 400 students: their GRE scores, GPA, class rank (split into categories 1, 2, 3, 4), and whether or not they were admitted (0 - rejected, 1 - accepted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "P_VPMREY36gA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a33a1c247ce559df7f10076494fac02",
     "grade": false,
     "grade_id": "cell-fa532de99ed0e2bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's do some data pre-processing.  We will first convert the rank categorical variable into a one hot encoding using the [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:37.870494Z",
     "start_time": "2020-02-17T23:40:37.850000Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "izueouBz36gB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_1  rank_2  rank_3  rank_4\n",
       "0       0       0       1       0\n",
       "1       0       0       1       0\n",
       "2       1       0       0       0\n",
       "3       0       0       0       1\n",
       "4       0       0       0       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_one_hot = pd.get_dummies(df['rank'], prefix='rank')\n",
    "rank_one_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "jIBPZxnW36gE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a2a0302d143eefa761290e89d81f72f",
     "grade": false,
     "grade_id": "cell-7add658e968d2489",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll add the one hot encoded features to the data frame and drop the original rank feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:38.226933Z",
     "start_time": "2020-02-17T23:40:38.216127Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sb_VKyhw36gF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0      0  380  3.61       0       0       1       0\n",
       "1      1  660  3.67       0       0       1       0\n",
       "2      1  800  4.00       1       0       0       0\n",
       "3      1  640  3.19       0       0       0       1\n",
       "4      0  520  2.93       0       0       0       1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, rank_one_hot], axis = 1)\n",
    "df.drop(['rank'], axis = 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Ex6JBBQT36gI",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39f988e4e0b178a5b9d98af5c5a4dae2",
     "grade": false,
     "grade_id": "cell-2e0901a029424e28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's split the data into a training set and a testing set.  We can use scikit-learn's [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:38.652941Z",
     "start_time": "2020-02-17T23:40:38.647993Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "A7XlBZ_Z36gI"
   },
   "outputs": [],
   "source": [
    "data = df.values # convert to numpy matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[:,1:], data[:,0], test_size=.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wt1qpgua36gM"
   },
   "source": [
    "We will standardize the GRE and GPA features to be zero mean and unit variance.  The [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) package from scikit-learn has useful functions to help us with this.  Notice that we scale the test data using the statistics from the *training* set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:39.025122Z",
     "start_time": "2020-02-17T23:40:39.020735Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "UQZ_U7Ja36gM"
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train[:,0:2]) # useful for applying the same scaling to the test data\n",
    "X_train[:,0:2] = scaler.transform(X_train[:,0:2])\n",
    "X_test[:,0:2] = scaler.transform(X_test[:,0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "E3q4zrGD36gQ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c34a654e56bde801de47be0616d2bd43",
     "grade": false,
     "grade_id": "cell-c84aec0bb7264538",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that our data is pre-processed, we will train a [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model using scikit-learn and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:48.949671Z",
     "start_time": "2020-02-17T23:54:48.935802Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-UFoQcsE36hB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(penalty = 'none', solver='lbfgs') # make an instance of the model\n",
    "lr_model.fit(X_train, y_train) # learn model weights\n",
    "predictions = lr_model.predict(X_test) # predictions on entire test dataset\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T07:40:13.393427Z",
     "start_time": "2020-02-06T07:40:13.384196Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "hytcOtRt36g8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7dfecf3a357bc4080c34b8317044148",
     "grade": false,
     "grade_id": "cell-747c420315b7872a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.20178059,  0.32587007,  0.81563491,  0.11295076, -0.61488503,\n",
       "         -0.9924196 ]]),\n",
       " array([-0.67871896]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coef_, lr_model.intercept_ # the learned weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "NFGH9k8I36gR",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85f54f7a1f9e73c92c6c9e34a60d3b95",
     "grade": false,
     "grade_id": "cell-7744578cac529dba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your goal below is to try to replicate these results, but using your own implementation of logistic regression from scratch.  Your model should not include a bias, so it should have 6 learned weights.  (Note that since some of the features are one-hot encoded variables, the bias term can be absorbed into the coefficients on the one-hot encoded inputs.)  In your work, you should include the following:\n",
    "- A derivation of the error gradients using a logistic loss function with L2 regularization\n",
    "- Complete the compute_lr_outputs, compute_logistic_loss, compute_total_loss, compute_lr_grad, and grad_checking_lr functions below.  Verify that your implementation passes gradient checking.\n",
    "- Experiment with different hyperparameter values for the learning rate, number of training iterations, L2 regularization weight, etc.  Find a setting that results in learned weights that agree with the weights that the scikit-learn model learned.  Explain any differences you see between your model's weights and the scikit-learn model's weights.\n",
    "- Include a plot of loss vs iteration for your selected hyperparameter settings, as well as estimated model weights and accuracy on the test data.\n",
    "\n",
    "Part of your grade will be on the readability of your writeup and code, so make sure to decompose and comment your code appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "OFTPOAGv36gS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "516b8688271f3700656d5a49c092efd6",
     "grade": true,
     "grade_id": "cell-8be4aa6308bf4019",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Derivation of error gradient for logistic loss function with L2 regularization**\n",
    "\n",
    "#### What is the form of the logistic regression model?  Express the prediction $\\hat{y}_i$ in terms of model weights $w$ and input $x_i$.\n",
    "\n",
    "From class, the logitic model is given by:\n",
    "\n",
    "$\\hat{y} = (wX)$\n",
    "\n",
    "or for one input\n",
    "\n",
    "\n",
    "$\\hat{y}_i = (wx_i)$\n",
    "#### What is the logistic loss function with L2 regularization?  (mean logistic loss plus $\\lambda w^T w$ term)\n",
    "\n",
    "From class, the loss is given by:\n",
    "\n",
    "J_Regularization = $\\frac{1}{N} \\Sigma_{i=1}^n(-y_i log(\\hat{y}_i) - (1-y_i)log(1-\\hat{y}_i)) + \\lambda w^T w$\n",
    "\n",
    "If we make vectors Y and P of our targets $y_i$ and predictions $\\hat{y}_i$ respectively, this becomes:\n",
    "\n",
    "J = $\\frac{1}{N}(-Ylog(P) - (1-Y)log(1-P))+ \\lambda w^T w$  \n",
    "\n",
    "#### What is the gradient of the loss with respect to parameter $w_k$?\n",
    "\n",
    "\n",
    "I'll use a computational graph\n",
    "\n",
    "Splitting the loss with L2 into functions for the computational graph.\n",
    "\n",
    "Let:\n",
    "\n",
    "z = $wX$    \n",
    "p = $(z)$    \n",
    "l = $\\frac{1}{N}(-Ylog(P) - (1-Y)log(1-P))$   \n",
    "R = $w^T w$  \n",
    "J = $L+\\lambda R$\n",
    "\n",
    "\n",
    "Taking our derivatives along the computational graph:  \n",
    "First, find the derivative of z with respect to w:  \n",
    "$\\frac{dz}{dw} = X$  \n",
    "\n",
    "\n",
    "Second, find the derivative of p with respect to z:  \n",
    "$\\frac{dp}{dz} = (1-(z))(z)$  \n",
    "\n",
    "Third, take the derivative of l with respect to p:  \n",
    "$\\frac{dl}{dp} =\\frac{1}{N}( \\frac {-Y}{P} - \\frac {(1-Y)}{(1-P)})$  \n",
    "\n",
    "Fourth, take the derivative of the loss with respect to l:  \n",
    "$\\frac{dJ}{dl} = 1$  \n",
    "\n",
    "To account for regularizations, we also need to incorporate that term into our graph. First, find the derivative of our regularization term with respect to w:  \n",
    "$\\frac{dR}{dw} = 2w$\n",
    "\n",
    "Second, find the derivative of our loss function with respect to regularization term:  \n",
    "$\\frac{dJ}{dR} = \\lambda$\n",
    "\n",
    "\n",
    "Now we can find all of the derivatives of our weights. Following the chain rule:  \n",
    "$\\frac{dJ}{dw} = \\frac{dJ}{dl}\\frac{dl}{dp}\\frac{dp}{dz}\\frac{dz}{dw} + \\frac{dJ}{dR}\\frac{dR}{dw}$   \n",
    " \n",
    "Where all the derivatives are defined above. This creates a vector of gradients for the weights w. To find the gradient of a specific weight $w_k$, I can simply take that element of the vector!\n",
    "\n",
    "In compute_lr_grad, I use the computer to calculate the value of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:39.753864Z",
     "start_time": "2020-02-17T23:40:39.749467Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "PGgBWXyv36gT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b974c5eae7b0b3a77eb589e84f5c5369",
     "grade": true,
     "grade_id": "cell-9957c7bc3e6230ce",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_lr_outputs(X, w):\n",
    "    '''\n",
    "    Inputs\n",
    "      X: numpy array containing the input data, size: numDataPts x numPredictors\n",
    "      w: numpy array containing the model weights, size: numPredictors\n",
    "      \n",
    "    Returns\n",
    "      y_hat: numpy array containing the model outputs (i.e. probabilities)\n",
    "    '''\n",
    "    # Return model outputs\n",
    "    y_hat = 1/(1+np.exp(-1*X.dot(w)))\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:39.938411Z",
     "start_time": "2020-02-17T23:40:39.933189Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "zYhCkAc936gV",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e158f149f36233710cf73395914b8eaf",
     "grade": true,
     "grade_id": "cell-4849ba10b3d3bcc2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test of correctess\n",
    "ans = compute_lr_outputs(np.array([[1,2],[3,4],[5,6]]),np.array([1/3,1/9]))\n",
    "assert(np.allclose(ans, np.array([0.63542356, 0.80914196, 0.91160032]), atol=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:40.130984Z",
     "start_time": "2020-02-17T23:40:40.127732Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "NpYrK6Ol36gX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7f0396a4b0d29a3b034b1c7a3fca8a6",
     "grade": true,
     "grade_id": "cell-79ced2cb4f8226d8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_logistic_loss(y, y_hat):\n",
    "    '''\n",
    "    Inputs\n",
    "      y: numpy array containing ground truth labels\n",
    "      y_hat: numpy array containing predicted outputs\n",
    "      \n",
    "    Returns\n",
    "      J: average logistic loss across all predictions (scalar)\n",
    "    '''\n",
    "    # plug into the log loss function\n",
    "    N = y.size\n",
    "    J = (-y.dot(np.log(y_hat)) - (1-y).dot(np.log(1-y_hat)))/N\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:40:40.325317Z",
     "start_time": "2020-02-17T23:40:40.320357Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "eYINqkoS36ga",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6a4e900bc57d3b05d873e9be9d42f68",
     "grade": true,
     "grade_id": "cell-d9e3a7cc9cd51ecd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test of correctness\n",
    "ans = compute_logistic_loss(np.array([0,1,1]),np.array([.6,.7,.8]))\n",
    "assert(np.allclose(ans, 0.49870307570903244, atol=.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66c42a0cb55a23a4481fedce0ab02d39",
     "grade": true,
     "grade_id": "cell-52eeee7eaf2ad819",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_total_loss(y, y_hat, w, lambd):\n",
    "    '''\n",
    "    Computes logistic loss with L2 regularization.\n",
    "    \n",
    "    Inputs\n",
    "      y: numpy array containing ground truth labels\n",
    "      y_hat: numpy array containing predicted outputs \n",
    "      w: numpy array containing the model weights\n",
    "      lambd: L2 regularization penalty weight\n",
    "      \n",
    "    Returns\n",
    "      loss: return the value of the loss function (including the regularization penalty)\n",
    "    '''\n",
    "    # Use log loss with a regularization term\n",
    "    N = y.size\n",
    "    loss = (-y.dot(np.log(y_hat)) - (1-y).dot(np.log(1-y_hat)))/N + lambd * w.dot(w)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31afd4648921fbe9a8994744cd4a183f",
     "grade": true,
     "grade_id": "cell-a9ce27f7500ad2c4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test of correctness\n",
    "ans = compute_total_loss(np.array([0,1,1]),np.array([.6,.7,.8]), np.array([1,2,3]), 1)\n",
    "assert(np.allclose(ans, 14.498703075709033, atol=.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:28.426787Z",
     "start_time": "2020-02-17T23:54:28.422189Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "xM_TE0uf36gd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1aa964fdf37aad720f02df134b9cd75",
     "grade": true,
     "grade_id": "cell-e4031a42d5a7791f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_lr_grad(X, y, w, lambd = 0):\n",
    "    '''\n",
    "    Computes error gradient for logistic regression function.\n",
    "    \n",
    "    Inputs\n",
    "      X: numpy array containing the input data\n",
    "      y: numpy array containing the target values\n",
    "      w: numpy array containing all model weights\n",
    "      lambd: L2 regularization penalty weight\n",
    "      \n",
    "    Returns\n",
    "      grad: numpy array containing the gradient of loss with respect to all model weights\n",
    "    '''\n",
    "\n",
    "    N = y.size\n",
    "    #Plug in values to calculate z,p,J,R,Lreg as defined above\n",
    "    z = X.dot(w)\n",
    "    p = 1/(1+np.exp(-1*z))\n",
    "    l = 1/N*((-y.dot(np.log(p)) - (1-y).dot(np.log(1-p))))\n",
    "    R = w.dot(w)\n",
    "    J = l + lambd*R\n",
    "    #Find our partial derivatives\n",
    "    dJdR = lambd\n",
    "    dJdl = 1\n",
    "    dldy = 1/N*(-y *1/p +(1-y)*1/(1-p))\n",
    "    dydz = (1-p)*p\n",
    "    dzdw = X\n",
    "    dRdw = 2*w\n",
    "    #Chain rule for gradient\n",
    "    grad = ((dJdl * dldy * dydz).dot(dzdw) + dJdR*dRdw)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:29.091421Z",
     "start_time": "2020-02-17T23:54:29.086638Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "ai29L9X536gi",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41cafa700607d6548843837cec2e1935",
     "grade": true,
     "grade_id": "cell-7339121f26dea58a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test of correctness\n",
    "ans = compute_lr_grad(np.array([[1,2],[3,4],[5,6]]),np.array([0,1,1]),np.array([1.2, -2.5]), 1)\n",
    "assert(np.allclose(np.array([-0.25750845, -8.3162873 ]), ans, atol=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:31.834840Z",
     "start_time": "2020-02-17T23:54:31.828682Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "lKD9xqmj36gq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "860bfb2c008a4bd7e78c04e6d5116775",
     "grade": true,
     "grade_id": "cell-90f6525b16cac750",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def grad_checking_lr(x, y, w, lambd = 0, eps = 1e-7):\n",
    "    '''\n",
    "    Performs gradient checking on a single (x,y) data point\n",
    "    \n",
    "    Inputs\n",
    "      x: numpy array containing the predictors for a single data point\n",
    "      y: scalar output\n",
    "      w: numpy array containing the model weights\n",
    "      lambd: L2 regularization penalty weight\n",
    "      eps: tolerance for gradient checking\n",
    "      \n",
    "    Returns\n",
    "      isCorrect: boolean indicating whether gradient checking passes or fails\n",
    "    '''\n",
    "    x = x.reshape((1,-1))\n",
    "    y = np.array([y])\n",
    "    grad = compute_lr_grad(x, y, w, lambd)\n",
    "    grad_approx = np.zeros_like(grad)\n",
    "    for i in range(len(grad)):\n",
    "        delta = np.zeros_like(grad)\n",
    "        delta[i] = eps\n",
    "         #Move the weights slightly and find the value\n",
    "        yPlus = compute_total_loss(y,compute_lr_outputs(x, w + delta),w+delta,lambd)\n",
    "        yMinus = compute_total_loss(y,compute_lr_outputs(x, w - delta),w-delta,lambd)\n",
    "        #Calcualate approximate gradient\n",
    "        grad_approx[i] = (yPlus - yMinus)/(2*eps)\n",
    "    num = np.linalg.norm(grad - grad_approx)\n",
    "    denom = np.linalg.norm(grad) + np.linalg.norm(grad_approx)\n",
    "    diff = num / denom\n",
    "    if diff < eps:\n",
    "        print('Passes gradient checking')\n",
    "        return True\n",
    "    else:\n",
    "        print('Fails gradient checking')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "dEylj0RN36gs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c98dc62348551422e284dd827278b13",
     "grade": false,
     "grade_id": "cell-e8981324c48945aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check that your implementation passes gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:32.706020Z",
     "start_time": "2020-02-17T23:54:32.700319Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "PEax1PE736gt",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1670d563eb8aed15a625c20fc0d28ff6",
     "grade": true,
     "grade_id": "cell-562ddb48114ef7ad",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passes gradient checking\n"
     ]
    }
   ],
   "source": [
    "params = np.array([1.2, -2.5, .2, -.7, .8, -2.1]) \n",
    "assert(grad_checking_lr(X_train[0], y_train[0], params, lambd = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ba775aa8b8432f3b09165cd8feb8b9b",
     "grade": true,
     "grade_id": "cell-9ba7744a862956dd",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passes gradient checking\n"
     ]
    }
   ],
   "source": [
    "params = np.array([1.2, -2.5, .2, -.7, .8, -2.1]) \n",
    "assert(grad_checking_lr(X_train[0], y_train[0], params, lambd = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:35.335108Z",
     "start_time": "2020-02-17T23:54:35.329933Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "G6X4qGLv36gv",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "136afb0bf3e6a0fcaffac4d6aaf63b37",
     "grade": true,
     "grade_id": "cell-eca9be9e29f33bf5",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_lr_model(X, y, lr, iters, lambd = 0, seed = 0):\n",
    "    '''\n",
    "    Fit logistic regression model to data.\n",
    "    \n",
    "    Inputs:\n",
    "        X - numpy array of inputs, size: numDataPoints x numPredictors\n",
    "        y - numpy array of targets\n",
    "        lr - learning rate\n",
    "        iters - number of iterations to train\n",
    "        lambd - regularization penalty weight\n",
    "        seed - for random number generation\n",
    "    \n",
    "    Returns:\n",
    "        params - estimated model weights\n",
    "        loss_traj - history of loss value at each iteration\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    params = np.random.normal(0, 1, X.shape[1]) \n",
    "    loss_traj = []\n",
    "    \n",
    "    for n in range(iters):\n",
    "        #Calculate z and p in order to get loss\n",
    "        N = x.size\n",
    "        z = X.dot(params)\n",
    "        p = 1/(1+np.exp(-1*z))\n",
    "        loss = compute_total_loss(y,p,params,lambd)\n",
    "        loss_traj.append(loss)\n",
    "        #Use function from above for the gradient and step weights\n",
    "        grad = compute_lr_grad(X,y,params,lambd)\n",
    "        params = params - lr * grad\n",
    "        \n",
    "    loss_traj = np.array(loss_traj)\n",
    "    return params, loss_traj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "899f38a23e967be2bda4cf14f9d5d8dd",
     "grade": false,
     "grade_id": "cell-49efbf2c1318de06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here is a helper function for visualizing a model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:36.012339Z",
     "start_time": "2020-02-17T23:54:36.005869Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "51vWBc3l36gy"
   },
   "outputs": [],
   "source": [
    "def display_losses_and_accuracy(losses, w, X_test, y_test):\n",
    "    '''\n",
    "    Plots training loss vs iteration and shows model parameters & test accuracy.\n",
    "    \n",
    "    Inputs:\n",
    "        losses - history of training loss at each epoch\n",
    "        w - model parameters\n",
    "        X_test - test inputs\n",
    "        y_test - test target values\n",
    "    '''\n",
    "    plt.plot(losses, 'b.')\n",
    "    plt.title('MSE vs Iteration')\n",
    "    plt.show()\n",
    "    predictions = np.round(compute_lr_outputs(X_test, w))\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    np.set_printoptions(precision=3)\n",
    "    print(\"Estimated Model Parameters: \", w)\n",
    "    print(\"Test Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T23:54:36.656823Z",
     "start_time": "2020-02-17T23:54:36.638941Z"
    },
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "E-F1NYyD36g0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "434ca17cd2570220f199aae075670211",
     "grade": true,
     "grade_id": "cell-b15b5ee083811cb6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Model Parameters:  [ 0.202  0.326  0.137 -0.566 -1.293 -1.67 ]\n",
      "Test Accuracy:  0.6875\n",
      "\n",
      "Sckit model produced these weights: \n",
      "[[ 0.202  0.326  0.816  0.113 -0.615 -0.992]]\n",
      "and this bias:\n",
      "[-0.679]\n",
      "\n",
      "\n",
      "\n",
      "If you add the bias to the last four weights of the Sckit model:\n",
      "[[ 0.202  0.326  0.137 -0.566 -1.294 -1.671]]\n",
      "Ill explain why this matches my weights in the final section\n"
     ]
    }
   ],
   "source": [
    "# Plot loss trajectory & evaluate test accuracy for lambda value #1\n",
    "w, losses = fit_lr_model(X_train,y_train,0.1, 5000, 0.00001)\n",
    "display_losses_and_accuracy(losses, w, X_test, y_test)\n",
    "print('\\nSckit model produced these weights: ')\n",
    "print(lr_model.coef_)\n",
    "print('and this bias:')\n",
    "print(lr_model.intercept_)\n",
    "print('\\n\\n\\nIf you add the bias to the last four weights of the Sckit model:')\n",
    "new_lr = lr_model.coef_ + np.array([0,0,1,1,1,1])*lr_model.intercept_\n",
    "print(new_lr)\n",
    "print('Ill explain why this matches my weights in the final section')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "id": "8DIm2pwZ36g8",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2264668dfb6e352ca32d08da530885a6",
     "grade": true,
     "grade_id": "cell-1ceb887041b9193f",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Discuss your observations here** \n",
    "\n",
    "Explain any differences you see between your model's weights and the scikit-learn model's weights.\n",
    "\n",
    "#### Similarities\n",
    "Generally, the weights appear to be doing the same thing. The first three weights are positive(as expected), since having a high GPA, gre, and class rank should correlate positively with admissions chances. The 3rd-6th weights also trend negatively in both models(by this I mean the 6th is smaller than the 5th, which is smaller than the 4th, etc..). This is the case since it is less beneficial to be towards the back of your class. Also, the test accuracy is reported to be the same as the Sckit model.\n",
    "\n",
    "\n",
    "#### Differences that actually aren't differences\n",
    "The only significant difference is the weights for class ranks. However, even this difference goes away when you consider the bias term that Sckit uses. Since the ranks are one hot encoded, only one can be present at a time, and the value is always one. So, the bias can effectively be incorporated into the weights for the class ranks:\n",
    "\n",
    "In the Sckit approach, there is a weight for the nonzero rank and there is a bias b. So the prediction is:\n",
    "\n",
    "$p =  (w_0*gre +w_1*gpa + w_r*1 + b)$\n",
    "where w_r is the weight that gets multiplied by the nonzero, one hot encoded rank\n",
    "\n",
    "Mathematically, this is the exact same result as my model, except the bias is incorporated into w_r:\n",
    "$p =  (w_0*gre +w_1*gpa + (w_r+b)*1)$\n",
    "\n",
    "So, even though the model weights look differently initially, they are the same once the bias from Sckit is incorporated into the categorical rank varaible. Once this adjustment is made, the models have the same weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a1fc46e7b627bad2594e9310da04ec1",
     "grade": true,
     "grade_id": "cell-d65bc7220cf52d28",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# intentionally empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4ce9b58974eeb7bfaa4d1cd7715765b",
     "grade": true,
     "grade_id": "cell-b661d8bc81af1aaf",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# intentionally empty"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "eng208-hw3-final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
